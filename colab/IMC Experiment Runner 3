{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IMC Experiment Runner 3","provenance":[{"file_id":"1YpYeKFw5Hflr2jO1lkU5pQ1cy-kA4OPw","timestamp":1585856378914}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cdPUZ0EkO30Y","colab_type":"text"},"source":["\n","## General Set Up"]},{"cell_type":"code","metadata":{"id":"rz5ySeTcA9Si","colab_type":"code","outputId":"0ceafbef-fda5-4e74-94d0-72d66c2598b0","executionInfo":{"status":"ok","timestamp":1589542116884,"user_tz":-120,"elapsed":31595,"user":{"displayName":"Elias Vansteenkiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJvt9gWcOir8b5OKmxkxztmhbDhGJTjoPKQav4Iw=s64","userId":"01507479926466879512"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Mount your Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Setting working directory\n","%cd /content/gdrive/My\\ Drive/imc/hibashi\n","!ls .\n","\n","# Installing Requirements\n","!pip install sacred==0.7.5 pytorch-ignite==0.2.1 tensorboardX==2.0 kornia==0.2.0 imgaug==0.4.0\n","\n","# Copy the data from Google Drive and extract it\n","!apt-get install rsync p7zip\n","!rsync -ash --progress '/content/gdrive/My Drive/datasets/fashion-dataset.zip' /home\n","!7z x  '/home/fashion-dataset.zip' -o/home "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive/imc/hibashi\n","experiment.py  __pycache__  README.md.rej     run.py   system\n","hibashi        README.md    requirements.txt  scripts  tests\n","Collecting sacred==0.7.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/89/bd8a71138906b146eea621505236f8704a3eeab2b9668aad77691b93fdb8/sacred-0.7.5-py2.py3-none-any.whl (92kB)\n","\u001b[K     |████████████████████████████████| 102kB 4.1MB/s \n","\u001b[?25hCollecting pytorch-ignite==0.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/31/efcc2b587419b1f54c5c6ef51996f91bb5d8f760537d17de674c89e06048/pytorch_ignite-0.2.1-py2.py3-none-any.whl (84kB)\n","\u001b[K     |████████████████████████████████| 92kB 7.9MB/s \n","\u001b[?25hCollecting tensorboardX==2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 15.0MB/s \n","\u001b[?25hCollecting kornia==0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/c137c3d0cc52a856d3f80ccc37281cc558df8c0b6b5f54d4cd78f4c3fb99/kornia-0.2.0-py2.py3-none-any.whl (142kB)\n","\u001b[K     |████████████████████████████████| 143kB 14.8MB/s \n","\u001b[?25hCollecting imgaug==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n","\u001b[K     |████████████████████████████████| 952kB 18.2MB/s \n","\u001b[?25hCollecting py-cpuinfo>=4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/60/63f28a5401da733043abe7053e7d9591491b4784c4f87c339bf51215aa0a/py-cpuinfo-5.0.0.tar.gz (82kB)\n","\u001b[K     |████████████████████████████████| 92kB 10.7MB/s \n","\u001b[?25hRequirement already satisfied: docopt<1.0,>=0.3 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.5) (0.6.2)\n","Collecting colorama>=0.4\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.5) (1.12.1)\n","Collecting jsonpickle<1.0,>=0.7.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/d5/2f47f03d3f64c31b0d7070b488274631d7567c36e81a9f744e6638bb0f0d/jsonpickle-0.9.6.tar.gz (67kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.5) (20.3)\n","Collecting munch<3.0,>=2.0.2\n","  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite==0.2.1) (1.5.0+cu101)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0) (1.18.4)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0) (3.10.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from kornia==0.2.0) (7.0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (1.4.1)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (1.7.0)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (0.16.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (2.4.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (4.1.2.30)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (3.2.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=18.0->sacred==0.7.5) (2.4.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-ignite==0.2.1) (0.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX==2.0) (46.1.3)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.4)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4.0) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4.0) (0.10.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug==0.4.0) (4.4.2)\n","Building wheels for collected packages: py-cpuinfo, jsonpickle\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-cp36-none-any.whl size=18684 sha256=eb2bfc1dd03e2f49945accb17cacef90a9b263eb0036e13089ba131c8a5f626b\n","  Stored in directory: /root/.cache/pip/wheels/01/7e/a9/b982d0fea22b7e4ae5619de949570cde5ad55420cec16e86a5\n","  Building wheel for jsonpickle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonpickle: filename=jsonpickle-0.9.6-cp36-none-any.whl size=29466 sha256=ed189040e4f2373c8e98ac4f1d439b831d9ee7f5d5593c398091178b030393f5\n","  Stored in directory: /root/.cache/pip/wheels/07/8b/41/8ce98f4737a9ff61b1bf2673f2abfe66a6a43ad6e91d2c9736\n","Successfully built py-cpuinfo jsonpickle\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.4.0 which is incompatible.\u001b[0m\n","Installing collected packages: py-cpuinfo, colorama, jsonpickle, munch, sacred, pytorch-ignite, tensorboardX, kornia, imgaug\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed colorama-0.4.3 imgaug-0.4.0 jsonpickle-0.9.6 kornia-0.2.0 munch-2.5.0 py-cpuinfo-5.0.0 pytorch-ignite-0.2.1 sacred-0.7.5 tensorboardX-2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IUkU7TVgqDmN","colab_type":"text"},"source":["## Setup Tensorboard\n","Change the path to include the tensorboard log files. The path will depend on where you put the interview task files in your Google Drive."]},{"cell_type":"code","metadata":{"id":"h9MOhHmhqMND","colab_type":"code","colab":{}},"source":["%load_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iaoUurBj84Lg","colab_type":"code","colab":{}},"source":["tensorboard --logdir '/content/gdrive/My Drive/tensorboard_logs/modegen'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rWRdPgYdet-j","colab_type":"text"},"source":["# Training\n","Command to train the mode generator"]},{"cell_type":"code","metadata":{"id":"6nfolO-eeuxm","colab_type":"code","outputId":"35144be0-1669-4fb1-b250-e2614117f0a0","executionInfo":{"status":"ok","timestamp":1589300203957,"user_tz":-120,"elapsed":27599480,"user":{"displayName":"Elias Vansteenkiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJvt9gWcOir8b5OKmxkxztmhbDhGJTjoPKQav4Iw=s64","userId":"01507479926466879512"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run.py --model pretrain -c \"5-RandomResizedCropFlip-constant_lr_2e-4\" with devices=[0] seed=37145"],"execution_count":0,"outputs":[{"output_type":"stream","text":["building ingredient_hook\n","hibashi.models.pretrain.losses hibashi.models\n","hibashi.models.pretrain.pretrain hibashi.models\n","ingredient_hook triggered\n","Setting seed to: 37145\n","INFO - root - cfg triggered\n","{}\n","INFO - pretrain - Storing metadata at: /content/gdrive/My Drive/tensorboard_logs/pretrain\n","INFO - pretrain - Running command 'run'\n","INFO - pretrain - Started\n","INFO - factory_hook - triggered\n","INFO - seed_hook - Setting seed to: 37145\n","INFO - set_username_hook - Setting user to: unknown\n","Warning: /content/gdrive/My Drive/tensorboard_logs/pretrain/5-RandomResizedCropFlip-constant_lr_2e-4 already exists.\n","INFO - zip_module_hook - Model successfully exported as model.zip\n","INFO - run - Starting the training process.\n","Printing out configuration:\n","{'devices': [0],\n"," 'model': {},\n"," 'params': {},\n"," 'seed': 37145,\n"," 'train': {'connect_mongo_db': False,\n","           'connect_slack': False,\n","           'eval_interval': 1000,\n","           'img_log_interval': 1000,\n","           'log_interval': 100,\n","           'metadata_path': '/content/gdrive/My Drive/tensorboard_logs',\n","           'n_epochs': 120,\n","           'overwrite_id_with': '5-RandomResizedCropFlip-constant_lr_2e-4',\n","           'save_interval': 1,\n","           'save_n_last': 5},\n"," 'train_data': {'aug_names': ['RandomResizedCropFlip'],\n","                'base_data_path': '/content/gdrive/My '\n","                                  'Drive/datasets/fashion-dataset',\n","                'batch_size': 32,\n","                'drop_last': True,\n","                'ds_params': {'aug_names': ['RandomResizedCropFlip'],\n","                              'base_data_path': '/content/gdrive/My '\n","                                                'Drive/datasets/fashion-dataset',\n","                              'images_rel_path': 'trimmed_images',\n","                              'sampler': 'RandomSampler',\n","                              'subsample': None},\n","                'images_rel_path': 'trimmed_images',\n","                'n_workers': 3,\n","                'name': 'FashionPretrainTrain',\n","                'sampler': 'RandomSampler',\n","                'shuffle': True,\n","                'subsample': None},\n"," 'user': 'unknown',\n"," 'val_data': {'FashionPretrainVal': {'aug_names': ['PadToSquareResize'],\n","                                     'base_data_path': '/content/gdrive/My '\n","                                                       'Drive/datasets/fashion-dataset',\n","                                     'batch_size': 32,\n","                                     'drop_last': False,\n","                                     'n_workers': 4,\n","                                     'sampler': 'SequentialSampler',\n","                                     'shuffle': False},\n","              'external_metrics': ['F1Jeans',\n","                                   'F1PerfumeAndBodyMist',\n","                                   'F1FormalShoes',\n","                                   'F1Socks',\n","                                   'F1Backpacks',\n","                                   'F1Belts',\n","                                   'F1Briefs',\n","                                   'F1Sandals',\n","                                   'F1FlipFlops',\n","                                   'F1Wallets',\n","                                   'F1Sunglasses',\n","                                   'F1Heels',\n","                                   'F1Handbags',\n","                                   'F1Tops',\n","                                   'F1Kurtas',\n","                                   'F1SportShoes',\n","                                   'F1Watches',\n","                                   'F1CasualShoes',\n","                                   'F1Shirts',\n","                                   'F1Tshirts'],\n","              'main_dataset': 'MNISTVal',\n","              'names': ['FashionPretrainVal']}}\n","Warning: /content/gdrive/My Drive/tensorboard_logs/pretrain/5-RandomResizedCropFlip-constant_lr_2e-4 already exists.\n","INFO - run - Validation dataset FashionPretrainVal: 3600\n","INFO - run - Train data: 14399\n","---------- Networks initialized -------------\n","ImageClassifier(\n","  (encoder): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n","  )\n","  (fc): Linear(in_features=2048, out_features=20, bias=True)\n",")\n","[Network net_classifier] Total number of parameters : 25.070 M\n","-----------------------------------------------\n","INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=120.\n","* Epoch [1/120]: [0/449]   0%|          , loss_accuracy=0, loss_cls=3.09 [00:00<?]INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=1.\n","INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:07:39\n","INFO - run - Validation Results for FashionPretrainVal - Epoch: 1  Avg loss: 0.137445\n","INFO - ignite.engine.engine.Engine - Engine run complete. Time taken 00:07:41\n","* Epoch [1/120]: [449/449] 100%|##########, loss_accuracy=0.846, loss_cls=0.46 [47:43<00:00]INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:48:03\n","INFO - run - Epoch 1 done. Time per batch: 0.164[s]\n","* Epoch [2/120]: [449/449] 100%|##########, loss_accuracy=0.875, loss_cls=0.366 [13:45<00:00]INFO - ignite.engine.engine.Engine - Epoch[2] Complete. Time taken: 00:13:51\n","INFO - run - Epoch 2 done. Time per batch: 0.199[s]\n","* Epoch [3/120]: [103/449]  23%|##2       , loss_accuracy=0.891, loss_cls=0.304 [03:08<09:55]INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=1.\n","INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:01:42\n","INFO - run - Validation Results for FashionPretrainVal - Epoch: 3  Avg loss: 0.909292\n","INFO - ignite.engine.engine.Engine - Engine run complete. Time taken 00:01:43\n","* Epoch [3/120]: [449/449] 100%|##########, loss_accuracy=0.893, loss_cls=0.326 [15:07<00:00]INFO - ignite.engine.engine.Engine - Epoch[3] Complete. Time taken: 00:15:14\n","INFO - run - Epoch 3 done. Time per batch: 0.199[s]\n","* Epoch [4/120]: [449/449] 100%|##########, loss_accuracy=0.903, loss_cls=0.292 [13:39<00:00]INFO - ignite.engine.engine.Engine - Epoch[4] Complete. Time taken: 00:13:44\n","INFO - run - Epoch 4 done. Time per batch: 0.197[s]\n","* Epoch [5/120]: [205/449]  46%|####5     , loss_accuracy=0.913, loss_cls=0.265 [06:08<07:07]INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=1.\n","INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:01:37\n","INFO - run - Validation Results for FashionPretrainVal - Epoch: 5  Avg loss: 0.908739\n","INFO - ignite.engine.engine.Engine - Engine run complete. Time taken 00:01:38\n","* Epoch [5/120]: [449/449] 100%|##########, loss_accuracy=0.91, loss_cls=0.263 [15:08<00:00]INFO - ignite.engine.engine.Engine - Epoch[5] Complete. Time taken: 00:15:14\n","INFO - run - Epoch 5 done. Time per batch: 0.204[s]\n","* Epoch [6/120]: [449/449] 100%|##########, loss_accuracy=0.922, loss_cls=0.241 [13:42<00:00]INFO - ignite.engine.engine.Engine - Epoch[6] Complete. Time taken: 00:13:50\n","INFO - run - Epoch 6 done. Time per batch: 0.206[s]\n","* Epoch [7/120]: [307/449]  68%|######8   , loss_accuracy=0.931, loss_cls=0.217 [09:10<04:37]INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=1.\n","INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:01:37\n","INFO - run - Validation Results for FashionPretrainVal - Epoch: 7  Avg loss: 0.902931\n","INFO - ignite.engine.engine.Engine - Engine run complete. Time taken 00:01:37\n","* Epoch [7/120]: [449/449] 100%|##########, loss_accuracy=0.923, loss_cls=0.202 [14:55<00:00]INFO - ignite.engine.engine.Engine - Epoch[7] Complete. Time taken: 00:15:02\n","INFO - run - Epoch 7 done. Time per batch: 0.198[s]\n","* Epoch [8/120]: [449/449] 100%|##########, loss_accuracy=0.924, loss_cls=0.214 [13:31<00:00]INFO - ignite.engine.engine.Engine - Epoch[8] Complete. Time taken: 00:13:38\n","INFO - run - Epoch 8 done. Time per batch: 0.200[s]\n","* Epoch [9/120]: [409/449]  91%|#########1, loss_accuracy=0.93, loss_cls=0.208 [12:30<01:27]INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=1.\n","INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:01:40\n","INFO - run - Validation Results for FashionPretrainVal - Epoch: 9  Avg loss: 0.914823\n","INFO - ignite.engine.engine.Engine - Engine run complete. Time taken 00:01:40\n","* Epoch [9/120]: [449/449] 100%|##########, loss_accuracy=0.927, loss_cls=0.196 [15:15<00:00]INFO - ignite.engine.engine.Engine - Epoch[9] Complete. Time taken: 00:15:21\n","INFO - run - Epoch 9 done. Time per batch: 0.200[s]\n","* Epoch [10/120]: [449/449] 100%|##########, loss_accuracy=0.936, loss_cls=0.183 [13:52<00:00]INFO - ignite.engine.engine.Engine - Epoch[10] Complete. Time taken: 00:13:59\n","INFO - run - Epoch 10 done. Time per batch: 0.204[s]\n","* Epoch [11/120]: [449/449] 100%|##########, loss_accuracy=0.935, loss_cls=0.189 [13:34<00:00]INFO - ignite.engine.engine.Engine - Epoch[11] Complete. Time taken: 00:13:41\n","INFO - run - Epoch 11 done. Time per batch: 0.201[s]\n","* Epoch [12/120]: [62/449]  14%|#3        , loss_accuracy=0.948, loss_cls=0.15 [01:46<11:33]INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=1.\n","INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:01:35\n","INFO - run - Validation Results for FashionPretrainVal - Epoch: 12  Avg loss: 0.917035\n","INFO - ignite.engine.engine.Engine - Engine run complete. Time taken 00:01:35\n","* Epoch [12/120]: [449/449] 100%|##########, loss_accuracy=0.939, loss_cls=0.163 [15:26<00:00]INFO - ignite.engine.engine.Engine - Epoch[12] Complete. Time taken: 00:15:33\n","INFO - run - Epoch 12 done. Time per batch: 0.203[s]\n","* Epoch [13/120]: [449/449] 100%|##########, loss_accuracy=0.932, loss_cls=0.188 [13:55<00:00]INFO - ignite.engine.engine.Engine - Epoch[13] Complete. Time taken: 00:14:01\n","INFO - run - Epoch 13 done. Time per batch: 0.202[s]\n","* Epoch [14/120]: [164/449]  37%|###6      , loss_accuracy=0.943, loss_cls=0.165 [05:05<11:07]INFO - ignite.engine.engine.Engine - Engine run starting with max_epochs=1.\n","INFO - ignite.engine.engine.Engine - Epoch[1] Complete. Time taken: 00:01:40\n","INFO - run - Validation Results for FashionPretrainVal - Epoch: 14  Avg loss: 0.916206\n","INFO - ignite.engine.engine.Engine - Engine run complete. Time taken 00:01:41\n","* Epoch [14/120]: [449/449] 100%|##########, loss_accuracy=0.946, loss_cls=0.152 [15:29<00:00]INFO - ignite.engine.engine.Engine - Epoch[14] Complete. Time taken: 00:15:36\n","INFO - run - Epoch 14 done. Time per batch: 0.203[s]\n","* Epoch [15/120]: [333/449]  74%|#######4  , loss_accuracy=0.951, loss_cls=0.136 [10:15<02:48]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pkqjBPAgvVLS","colab_type":"code","outputId":"a443a748-8533-4fe9-eb31-3b94c6469a18","executionInfo":{"status":"ok","timestamp":1587459498325,"user_tz":-120,"elapsed":4435,"user":{"displayName":"Elias Vansteenkiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSCDDQyh8HrNomWOuF4PUJsx_zKr4XwbcXYIqWhQ=s64","userId":"01507479926466879512"}},"colab":{"base_uri":"https://localhost:8080/","height":293}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Apr 21 08:58:09 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f-kc6z_08KYa","colab_type":"code","colab":{}},"source":["cp -r /Users/elias/Downloads/pretrain '/content/gdrive/My Drive/tensorboard_logs'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZa2Q_Tz9Z1k","colab_type":"code","outputId":"9aee4340-a964-400a-f7c8-c29639716fe2","executionInfo":{"status":"ok","timestamp":1589478667182,"user_tz":-120,"elapsed":2638,"user":{"displayName":"Elias Vansteenkiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJvt9gWcOir8b5OKmxkxztmhbDhGJTjoPKQav4Iw=s64","userId":"01507479926466879512"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["ls '/content/gdrive/My Drive/datasets/fashion-dataset/trimmed_images/51366.jpg'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'/content/gdrive/My Drive/datasets/fashion-dataset/trimmed_images/51366.jpg'\n"],"name":"stdout"}]}]}